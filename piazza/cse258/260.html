{"result":{"history_size":3,"folders":["assignment1"],"nr":260,"data":{"embed_links":[]},"created":"2024-11-12T00:12:38Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m3dp7ilzfkm7kp","v":"all","type":"create","when":"2024-11-12T00:12:38Z","uid_a":"a_0"},{"anon":"stud","data":"m3dp8gb2h551ez","v":"all","type":"update","when":"2024-11-12T00:13:22Z","uid_a":"a_0"},{"anon":"stud","data":"m3dp954culr2ru","v":"all","type":"update","when":"2024-11-12T00:13:54Z","uid_a":"a_0"},{"anon":"no","uid":"icbjgije2033xe","data":"m3i03xemkv65in","to":"m3dp7ilsa077ko","type":"i_answer","when":"2024-11-15T00:28:51Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"creating negative training data for read prediction","created":"2024-11-12T00:13:54Z","content":"<p>Hi, I am currently working on reading prediction. Do we need to create negative training data (user didn&#39;t read certain books) for reading prediction?</p>\n<p></p>\n<p>My current process is </p>\n<p>1. build a model using the training data</p>\n<p>2. test the model with validation set</p>\n<p>3. train a new model using training data and validation set to predict the test data on Gradescope</p>\n<p>If my current process is correct, I think I need to create negative training data as in homework 3 for the first step in my process. But if so, the training data size will be large, and my model training will take extremely long time every time (&gt; 10 minutes without results), because I have multiple features for the model, and getting the value for these features take time. So I wonder whether my understanding is correct, and whether I am on the right track.</p>\n<p></p>\n<p>Thank you!</p>"},{"anon":"stud","uid_a":"a_0","subject":"creating negative training data for read prediction","created":"2024-11-12T00:13:22Z","content":"<p>Hi, I am currently working on reading prediction. Do we need to create negative training data (user didn&#39;t read certain books) for reading prediction?</p>\n<p></p>\n<p>My current process is </p>\n<p>1. build a model using the training data</p>\n<p>2. test the model with validation set</p>\n<p>3. train a new model using training data and validation set to predict the test data on Gradescope</p>\n<p>If my current process is correct, I think I need to create negative training data as in homework 3 for the first step in my process. But if so, the training data size will be large, and my model training will take extremely long time every time (&gt; 10 minutes without results), because I have multiple features for the model, and getting the value for these features take time. So I wonder whether my understanding is correct, and whether I am on the right track.</p>"},{"anon":"stud","uid_a":"a_0","subject":"creating negative training data for read prediction","created":"2024-11-12T00:12:38Z","content":"<p>Hi, I am currently working on reading prediction. Do we need to create negative training data (user didn&#39;t read certain books) for reading prediction?</p>\n<p></p>\n<p>My current process is </p>\n<p>1. build a model using the training data</p>\n<p>2. test the model with validation set</p>\n<p>3. train a new model using training data and validation set to predict the test data on Gradescope</p>\n<p>If my current process is correct, I think I need to create negative training data for the first step. But if so, my model training will take extremely long time every time (&gt; 10 minutes without results), because I have multiple features for the model, and getting the value for these features take time. So I wonder whether my understanding is correct, and whether I am on the right track.</p>"}],"type":"question","tags":["assignment1","student"],"tag_good":[{"role":"student","name":"Michael Hennelly","endorser":{},"admin":false,"photo":null,"id":"m1fj3fvx3fm3tc","photo_url":null,"us":false,"facebook_id":null},{"role":"student","name":"Ruilong Liu","endorser":{},"admin":false,"photo":null,"id":"m182yqr75sl457","photo_url":null,"us":false,"facebook_id":null},{"role":"student","name":"Siddhanth Ramani","endorser":{},"admin":false,"photo":null,"id":"lmpga160gkj616","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":218,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-15T00:28:51Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Erica Cheng","endorser":{},"admin":false,"photo":null,"id":"m182ygrlgf83d9","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Yunhao Jiang","endorser":{},"admin":false,"photo":null,"id":"m182ypevmgf41p","photo_url":null,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"icbjgije2033xe","subject":"","created":"2024-11-15T00:28:51Z","content":"I think your understanding is correct. But not sure why it would result in a long training time? Presumably you&#39;re only computing a few features here, so training should be pretty quick. Would also stress that while the training data is big, you absolutely don&#39;t have to use all of it -- especially if fitting a model with just a few parameters, you certainly don&#39;t need 190k samples."}],"type":"i_answer","tag_endorse_arr":["m182ygrlgf83d9","m182ypevmgf41p"],"children":[],"id":"m3i03xe4sas5il","config":{"editor":"rte"},"is_tag_endorse":false}],"tag_good_arr":["m1fj3fvx3fm3tc","m182yqr75sl457","lmpga160gkj616"],"no_answer":0,"id":"m3dp7ilsa077ko","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":3,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731989359942,"default_anonymity":"no"},"error":null,"aid":"m3nxqv5n8zp8m"}