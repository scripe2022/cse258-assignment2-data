{"result":{"history_size":1,"folders":["assignment1"],"nr":300,"data":{"embed_links":[]},"created":"2024-11-17T00:43:19Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m3kvi8nzbof55q","v":"all","type":"create","when":"2024-11-17T00:43:19Z","uid_a":"a_0"},{"anon":"no","uid":"l8ahmcpvgej6dw","data":"m3l21jex9an29p","to":"m3kvi8ns2jj55o","type":"i_answer","when":"2024-11-17T03:46:17Z"},{"anon":"no","uid":"l8ahmcpvgej6dw","data":"m3l2obic9gm2t7","type":"i_answer_update","when":"2024-11-17T04:04:00Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"read predcition score on leaderboard","created":"2024-11-17T00:43:19Z","content":"<p>Hi, this may appear in some previous questions, but I am very confused about the read prediction score on the Gradescrope leaderboard. </p>\n<p></p>\n<p>For read prediction, i use some popularity feature and similarity features and try to fit a linear model over it. During this process i also created som negative data in the train dataset for linear model (similar to how we create negative data for validation set in HW3). After doing so, I am still getting (1/2) on gradescope and the score on leaderboard is much-much lower than my score when submitting a enhanced baseline similar to the implementation for Q3 in HW3, and the score is also a lot lower than the score when running the model on validation set... </p>\n<p></p>\n<p>I was wondering why this may happen..... or the &#34;create negative data for train dataset&#34; is not correct as it leaked data... </p>\n<p></p>\n<p>thank you so much in advance </p>"}],"type":"question","tags":["assignment1","student"],"tag_good":[],"unique_views":269,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-11-17T03:46:17Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"l8ahmcpvgej6dw","subject":"","created":"2024-11-17T04:04:00Z","content":"<md>From your description, it seems the model is overfitting to the training data - the model performs well on the training data but fails to generalize to unseen data. \n\nCreating negative data for training is fine.  \n\nRelated posts and suggestions: @295, @144, @289</md>"},{"anon":"no","uid":"l8ahmcpvgej6dw","subject":"","created":"2024-11-17T03:46:17Z","content":"<md>From your description, it seems the model is overfitting to the training data - the model performs well on the training data but fails to generalize to unseen data. \n\nRelated posts and suggestions: @295, @144, @289</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m3l21jeroqq29o","config":{"editor":"md"},"is_tag_endorse":false}],"tag_good_arr":[],"no_answer":0,"id":"m3kvi8ns2jj55o","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731989410587,"default_anonymity":"no"},"error":null,"aid":"m3nxry8bibi2r1"}