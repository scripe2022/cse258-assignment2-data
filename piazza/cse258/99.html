{"result":{"history_size":1,"folders":["other"],"nr":99,"data":{"embed_links":[]},"created":"2024-10-24T19:26:26Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2np24hfxwk3dt","v":"all","type":"create","when":"2024-10-24T19:26:26Z","uid_a":"a_0"},{"anon":"no","uid":"ln0saa4uy359r","data":"m2nw9ngmych607","to":"m2np24h7hma3dr","type":"i_answer","when":"2024-10-24T22:48:14Z"},{"anon":"stud","to":"m2np24h7hma3dr","type":"followup","when":"2024-10-25T01:26:16Z","cid":"m2o1wvlphze5t2","uid_a":"a_0"},{"anon":"no","uid":"ln0saa4uy359r","to":"m2np24h7hma3dr","type":"feedback","when":"2024-10-25T04:26:41Z","cid":"m2o8cw966qy6wk"},{"anon":"stud","to":"m2np24h7hma3dr","type":"feedback","when":"2024-10-25T07:56:44Z","cid":"m2ofv0xj7ih6d0","uid_a":"a_0"},{"anon":"stud","to":"m2np24h7hma3dr","type":"feedback","when":"2024-10-25T08:04:52Z","cid":"m2og5hadedi36j","uid_a":"a_0"},{"anon":"no","uid":"ln0saa4uy359r","to":"m2np24h7hma3dr","type":"feedback","when":"2024-10-25T23:01:34Z","cid":"m2pc6mumpj7429"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Lecture Follow-Up: Non-Convex Proof of Non-Linear Latent Factor Interaction and Linear Terms","created":"2024-10-24T19:26:26Z","content":"<md>How does matrix permutation imply the many local minima are independent and aren't all the same local minima?\n\nProf. responded that the $$k$$-dimension reduced $$U$$, and $$V$$ (like the user coordinates and the Harry Potter Coordinates), can be rotated to provide a minimum for those coordinates.\n\nI don't quite understand how doing corresponding vector swaps  (matrix permutations) in $$U$$ and $$V$$ lead to a set containing multiple local minima that are distinct. I though the permutation would just change the ordering of the coordinates that still represent the same minimum, which is why I was confused how this shows there more than one minima to prove non-convexity.</md>"}],"type":"question","tags":["other","student"],"tag_good":[],"unique_views":149,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-24T22:48:14Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0saa4uy359r","subject":"","created":"2024-10-24T22:48:14Z","content":"<md>Imagine you have\n\n$$\nU = (1, 0, 3, 2), I = (2, 1, 0, 2)\n$$\n\nwhich is the magical global minimum in the universe.\n\nIn this case, the \"global minimum\" is $$U^\\top I = 4$$.\n\nThen you can easily find multiple solutions with the same \"global minimum\" by swapping some columns in these matrices, like $$U' = (1, 3, 2, 0), I' = (2, 0, 2, 1)$$, and also $$U'' = (2, 3, 1, 0), I'' = (2, 0, 2, 1)$$\n\nThese new solutions have the same \"global minimum\" as $$U'^\\top I' = U''^\\top I'' = 4$$.\n\nSo it should not be some global minimum but instead multiple local minimums.</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2nw9ngggp6605","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<md>But aren't each of the $$'$$ and $$''$$ swaps that lead to the same global minimum, just the global minima in their own swapped spaces? \n\nIf so, aren't these swaps are just different representations of the same global minima? If so, what makes each global minima in each swapped space become distinct global minima for the original space?</md>","created":"2024-10-25T01:26:16Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>Consider a general function $$y = f(x)$$. In most optimization problems, the primary objective is often to find the value(s) of $$x$$ that yield the global minimum of $$f(x)$$, rather than the actual value of $$y$$.\n\nIf the function is convex, there exists a unique point $$x$$ (along with its local neighborhood) that minimizes $$f(x)$$ globally.\n\nHowever, as we previously discussed, there are multiple values, such as $$x, x', x''$$, that correspond to the global minimum, which contradicts the definition of a convex function.</md>","created":"2024-10-25T04:26:41Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid":"ln0saa4uy359r","children":[],"tag_good_arr":[],"id":"m2o8cw966qy6wk","d-bucket":"Yesterday","updated":"2024-10-25T04:26:41Z","config":{"editor":"md"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"<md>If\\\n$$A = U^T V$$\\\n$$B = U'^T V'$$\\\n$$C = U''^T V''$$\n\nWhat I understand about your claim is that $$x$$, $$x'$$, $$x''$$ are minimizers of each configuration - $$A$$, $$B$$, $$C$$ - and if we treat $$A$$, $$B$$,$$C$$ as the same \"problem space\" but just permuted, then $$x$$, $$x'$$, $$x''$$ are minimizers of any of $$A$$, $$B$$, $$C$$ (or any other permutation of theirs). \n\nWhat I don't understand is if  $$A \\neq B \\neq C$$ (since the affine transformations are permutations of each others; so they are distinct transformations -, which means they are not strictly equivalent), why the minimizer of $$A$$ (which is $$x$$), the minimizer of $$B$$ (which is $$x'$$), and  the minimizer of $$C$$ (which is $$x''$$) - why these minimizers (which are just permutations of one minimizer), are ***all*** valid minimizers for each A, B, C (or any other permutations).\n\n\n\nI'll likely attend OH to make sure I'm able to understand it, but let me know if these ideas are pointing to the right direction:\n\nChecking if $$A = B =C$$:\\\nif $$A = U^T V$$ and $$P$$ is a permutation matrix,\n\n$$B$$\\\n$$= U'^T V'$$\\\n$$= (PU)^T (PV)$$\\\n$$= U^T P^T (PV)$$\\\n$$= U^T (P^T P) V$$\\\n$$= U^T (I) V$$\\\n$$= U^T V$$\\\n$$= A$$\n\n$$C$$\\\n$$= U''^T V''$$\\\n$$= (P'U)^T (P'V) \\text{ //} P'\\text{ is another permutation of } P$$\\\n$$= U^T P'^T (P'V)$$\\\n$$= U^T (P'^T P') V$$\\\n$$= U^T (I) V$$\\\n$$= U^T V$$\\\n$$= A$$\n\nSo if $$x$$ minimizes $$A$$, $$x'$$ minimizes $$B$$, and $$x''$$ minimizes $$C$$ and $$A = B = C$$, then any of $$x$$,$$x'$$, $$x''$$ (which are just permutations of each other) minimizes each of $$A, B, C$$ (and their permutations), while $$x \\neq x' \\neq x''$$. (so no multiplicities of minima, which mean they are distinct minimizers).\n\nSo even though $$A, B, C$$ are distinct affine transformations, they represent \"the same problem space\"/\"structurally similar\"? So there's a equivalence of categories/isomorphism of matrices under permutation since the structure seems invariant among the different objects? \n\nI know that $$g(x) = (x-h)^2$$ is a convex function, with a multiplicity of 2 on the $$x=h$$ root. But multiplicity of 2 on $$x=h$$ means that, even though the solution are not distinct, there's more than 1 solution to $$(x-h)^2$$ (Satisfying the Fundamental Theorem of Algebra). But surely this can't mean $$(x-h)^2$$ is not convex, right? Parabolas are smooth, bowl-shaped functions with a unique minima at $$x=h$$ so they're convex (since multiplicity and convexity are not the same).\n\nSo for the permutations since $$x \\neq x' \\neq x''$$, they aren't the same minimizers but distinct due to them being permutations of each other representing different configurations of each local minima for the same problem. Since there are multiple local minima here, then we're non-convex?</md>","created":"2024-10-25T07:56:44Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2ofv0xj7ih6d0","d-bucket":"Yesterday","updated":"2024-10-25T07:56:44Z","config":{"editor":"md"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"<md>Sorry if the is a bit much, but wanted to make sure I'm understanding this:\n\nWhat if $$x, x', x''$$ were all permutations of each other, but the value in each index of the permutation was the same? Then $$x = x' = x''$$, which would then mean we have a multiplicity of solutions for $$A$$ (and it's permutations), which means we have 1 unique minimizer. \n\nUnder these conditions, would this imply $$A$$ is convex (and it’s permutations are all equivalent to one configuration)?</md>","created":"2024-10-25T08:04:52Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2og5hadedi36j","d-bucket":"Yesterday","updated":"2024-10-25T08:04:52Z","config":{"editor":"md"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>In extreme cases, like when all the values across the indices are the same, the function could indeed be convex. However, I believe the more interesting discussion is in the general case. I think the professor’s point is that in the context of typical recommender systems, latent factorization leads to a non-convex function, rather than suggesting that latent factorization can never degenerate into a convex function.</md>","created":"2024-10-25T23:01:34Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"ln0saa4uy359r","children":[],"tag_good_arr":[],"id":"m2pc6mumpj7429","updated":"2024-10-25T23:01:34Z","config":{"editor":"md"}}],"tag_good_arr":[],"no_answer":0,"id":"m2o1wvlphze5t2","updated":"2024-10-25T23:23:08Z","config":{"editor":"md"}}],"tag_good_arr":[],"no_answer":0,"id":"m2np24h7hma3dr","config":{"editor":"md","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731989156257,"default_anonymity":"no"},"error":null,"aid":"m3nxmhzo6zh3mq"}