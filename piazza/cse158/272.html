{"result":{"history_size":1,"folders":["hw3"],"nr":272,"data":{"embed_links":[]},"created":"2024-11-07T23:32:46Z","bucket_order":3,"no_answer_followup":2,"change_log":[{"anon":"stud","data":"m37y0umcvuy7hd","v":"all","type":"create","when":"2024-11-07T23:32:46Z","uid_a":"a_0"},{"anon":"no","uid":"lml4g5v8hzj1lc","data":"m37zblh6x524g4","to":"m37y0um6u7s7hc","type":"i_answer","when":"2024-11-08T00:09:07Z"},{"anon":"no","uid":"lml4g5v8hzj1lc","data":"m37zj2l6je41i","type":"i_answer_update","when":"2024-11-08T00:14:56Z"},{"anon":"stud","to":"m37y0um6u7s7hc","type":"followup","when":"2024-11-08T00:15:26Z","cid":"m37zjp92lwh381","uid_a":"a_0"},{"anon":"no","uid":"lml4g5v8hzj1lc","to":"m37y0um6u7s7hc","type":"feedback","when":"2024-11-08T00:17:19Z","cid":"m37zm4r6x5674s"},{"anon":"stud","to":"m37y0um6u7s7hc","type":"feedback","when":"2024-11-09T00:09:25Z","cid":"m39ertkyeku5km","uid_a":"a_0"},{"anon":"stud","to":"m37y0um6u7s7hc","type":"feedback","when":"2024-11-09T05:14:59Z","cid":"m39pos9sm7y6oq","uid_a":"a_1"},{"anon":"stud","uid_a":"a_2","to":"m37y0um6u7s7hc","type":"followup","when":"2024-11-12T16:21:41Z","cid":"m3entpozkqp2ee"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"HW 3 Q3 Logic","created":"2024-11-07T23:32:46Z","content":"<p>Hello, </p>\n<p></p>\n<p>I have been working on HW 3 Q3 for some time and haven&#39;t been able to get accuracy above around 0.68, so I am wondering whether my approach to the question is correct, or whether there&#39;s an issue with how I&#39;m attempting the problem. </p>\n<p></p>\n<p>I have a function somewhat similar to the rating prediction functions used in HW 2, which takes a (user, book) pair, and for each item in the corresponding itemsPerUser[user] set (skipping if the item is the query), calculates the Jaccard similarity between the usersPerItem[book] set and the usersPerItem[item] set. I store each similarity in a list, and compare the maximum of this list to the threshold. If the maximum Jaccard value exceeds the threshold, the function returns true, and otherwise it returns false. </p>\n<p></p>\n<p>Once I have predictions for every (user, book) pair in the validation set I created (with positive and negative samples), I iterate through the predictions for read/unread and compare them with the actual values of read/unread in the validation set. Accuracy is computed as the number of predictions that matched the validation set / 20000.  To me this makes sense, but I&#39;m not sure if there is something I&#39;m missing, since I have been using linspace to try very small values for the threshold, and still have not been able to get accuracy to reach even 0.69. </p>\n<p></p>\n<p>I was also wondering if there was a baseline for accuracy on Q1, because I originally had a value around 0.75, but adjusted my approach to creating the validation set and am now getting values around 0.71 for Q1. Is this reasonable, or should I be expecting something higher? I am not sure if that factors into the low accuracy I&#39;m seeing for Q3, or if there&#39;s something else wrong with my approach for the predictor, so if anyone has any suggestions or notices something off about how I am implementing it, I would appreciate any advice! Thank you!</p>"}],"type":"question","tags":["hw3","student"],"tag_good":[{"role":"student","name":"Madhoolika Chodavarapu","endorser":{},"admin":false,"photo":null,"id":"l7uh7ugnk6v275","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":292,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-11-08T00:09:07Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lml4g5v8hzj1lc","subject":"","created":"2024-11-08T00:14:56Z","content":"<md>Many students have an issue where usersPerItem[] and itemsPerUser[] are biased with data from ratingsValid, which casues them to fail to reach the desired accuracy. Your current approach to Q1 sounds fine, so your construction of the validation set is likely correct.</md>"},{"anon":"no","uid":"lml4g5v8hzj1lc","subject":"","created":"2024-11-08T00:09:07Z","content":"<md>Many students have an issue where usersPerItem[] and itemsPerUser[] are biased with data from ratingsValid, which casues them to fail to reach the desired accuracy.</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m37zblh0ecj4g3","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"I created usersPerItem[] and itemsPerUser[] based off the training data (ratingsTrain), so I don&#39;t think they should be affected by ratingsValid?","created":"2024-11-08T00:15:26Z","bucket_order":6,"bucket_name":"Last week","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>Then I would suggest refining your accuracy threshold search. One thing that can help is searching a range, plotting it, searching a narrower range, repeat until you find the optimal threshold. You likely need to search every .0001 values to reach the desired accuracy (which can be slow, so narrowing down the search might help you find it faster).</md>","created":"2024-11-08T00:17:19Z","bucket_order":6,"bucket_name":"Last week","type":"feedback","tag_good":[],"uid":"lml4g5v8hzj1lc","children":[],"tag_good_arr":[],"id":"m37zm4r6x5674s","updated":"2024-11-08T00:17:19Z","config":{"editor":"md"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"When I&#39;m searching ranges of very small values, the best threshold is reported as 0, and even with 0 as a threshold, I only get accuracy of 0.686. Is there anything else I can try to change about the function itself? I&#39;m not sure why I can&#39;t get my accuracy any better.","created":"2024-11-09T00:09:25Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[{"role":"student","name":"Keren Gutman","endorser":{"ktkpd9efwbklm":1637624548,"ky0h7ov6xs51ge":1642959911},"admin":false,"photo":null,"id":"ktxt65aeh6z6j7","photo_url":null,"us":false,"facebook_id":null}],"uid_a":"a_0","children":[],"tag_good_arr":["ktxt65aeh6z6j7"],"id":"m39ertkyeku5km","updated":"2024-11-12T15:43:25Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"I am also experiencing the same issues, I just had my predictor run for about 3 hours and it just ended up telling me 0 was the best threshold","created":"2024-11-09T05:14:59Z","bucket_order":6,"bucket_name":"Last week","type":"feedback","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"id":"m39pos9sm7y6oq","updated":"2024-11-09T05:14:59Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m37zjp92lwh381","updated":"2024-11-09T05:14:59Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"Same, I cannot get above 0.68","created":"2024-11-12T16:21:41Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_2","children":[],"tag_good_arr":[],"no_answer":1,"id":"m3entpozkqp2ee","updated":"2024-11-12T16:21:41Z","config":{"editor":"plain"}}],"tag_good_arr":["l7uh7ugnk6v275"],"no_answer":0,"id":"m37y0um6u7s7hc","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":5,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731986566718,"default_anonymity":"no"},"error":null,"aid":"m3nw2zvzl1k4mo"}