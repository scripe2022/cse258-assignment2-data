{"result":{"history_size":1,"folders":["hw3"],"nr":167,"data":{"embed_links":[]},"created":"2024-10-30T01:22:22Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m2v6z4bo66b43h","v":"all","type":"create","when":"2024-10-30T01:22:22Z","uid_a":"a_0"},{"anon":"no","uid":"l6cbdmaoju25me","data":"m2vcyfiujmg3wq","to":"m2v6z4bica143e","type":"s_answer","when":"2024-10-30T04:09:48Z"},{"anon":"stud","to":"m2v6z4bica143e","type":"followup","when":"2024-10-30T04:33:57Z","cid":"m2vdthls6e62sz","uid_a":"a_0"},{"anon":"no","uid":"l6cbdmaoju25me","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T04:35:55Z","cid":"m2vdw0ucr0y22a"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T04:51:40Z","cid":"m2vegaakxuw1tb","uid_a":"a_0"},{"anon":"no","uid":"l6cbdmaoju25me","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T04:56:08Z","cid":"m2vem0kylgvcd"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T05:07:09Z","cid":"m2vf06wlykg1b6","uid_a":"a_0"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T09:28:21Z","cid":"m2voc3kll28oq","uid_a":"a_1"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T16:17:22Z","cid":"m2w2y3jwsgf5q6","uid_a":"a_0"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T16:57:13Z","cid":"m2w4dcghg8l1ug","uid_a":"a_2"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T17:13:26Z","cid":"m2w4y6xmvkc3wc","uid_a":"a_0"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T17:17:23Z","cid":"m2w539twiqm52m","uid_a":"a_2"},{"anon":"stud","to":"m2v6z4bica143e","type":"feedback","when":"2024-10-30T18:22:38Z","cid":"m2w7f6yr30e54o","uid_a":"a_0"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"HW3 Q3 Accuracy Follow Up","created":"2024-10-30T01:22:22Z","content":"I know that accuracy requirement got dropped to 70% as even the TA have been having trouble getting above this accuracy. However, I have not been able to get above 69.8% consistently. I have tried finding the best threshold value through multiple ways (linspace, minimize_scalar) however I have not been able to find something that can get me past 69%. I cannot implement extra features into the model as that is what question 4 is about. To me it seems that there is a cutoff at 69%. Additionally, I noticed that the probability can change by up to 1% just from the random negative samples that are selected. One time I got lucky and was able to barely get 70% accuracy. However, this was off a random chance as was not reproducible. Some guidance would be nice. I feel like I am missing something or that the accuracy metric is too high."}],"type":"question","tags":["hw3","student"],"tag_good":[{"role":"student","name":"imholloway@ucsd.edu","endorser":{},"admin":false,"photo":null,"id":"m1fmuc1nxah1fd","photo_url":null,"us":false,"facebook_id":null},{"role":"student","name":"Dylan Tran","endorser":{},"admin":false,"photo":null,"id":"l871grkwo481d2","photo_url":null,"us":false,"facebook_id":null}],"unique_views":282,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-30T04:09:48Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"l6cbdmaoju25me","subject":"","created":"2024-10-30T04:09:48Z","content":"You only need linspace. You can get through it with some very small threshold. Totally reachable, try more thresholds."}],"type":"s_answer","tag_endorse_arr":[],"children":[],"id":"m2vcyfio77r3wp","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"I run linspace for 10000 from multiple ranges. Some of these ranges are 0 to 0.001, 0 to 0.0001, and 0 to 0.00001. There must be something else that is going on that allow you get the 70%. I still get 69%.","created":"2024-10-30T04:33:57Z","bucket_order":5,"bucket_name":"This week","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"Nope, nothing special, you probably just need to go deep into where the point it stops decreasing and starts increasing. Some more hint is none of the range you mentioned contains the optimal threshold. It is a little larger than what you have.","created":"2024-10-30T04:35:55Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid":"l6cbdmaoju25me","children":[],"tag_good_arr":[],"id":"m2vdw0ucr0y22a","updated":"2024-10-30T04:35:55Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"You might be right however I did the same test just now from range 0.001 and 1. I still do not hone in on something that is better than 69%. The best threshold for me in this case was 0.001. This contradicts what you were saying earlier so I am struggling to move forward.","created":"2024-10-30T04:51:40Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2vegaakxuw1tb","updated":"2024-10-30T04:51:40Z","config":{"editor":"rte"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"You might have done some other things incorrect. I did not did anything special. And the followups here might be helpful. <a href=\"/class/m119nkxb2n3xb/post/110\" target=\"_blank\" rel=\"noopener noreferrer\">https://piazza.com/class/m119nkxb2n3xb/post/110</a> ","created":"2024-10-30T04:56:08Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid":"l6cbdmaoju25me","children":[],"tag_good_arr":[],"id":"m2vem0kylgvcd","updated":"2024-10-30T04:56:08Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Maybe it is the way the validation set is setup. I randomly sample books the user has not read from all the book reviews. Is the correct way or should sample the training set only to the validation set. <div><br /></div><div>I definitely think I am doing the predictor correct as I am taking the max of all jaccard similarities and comparing it against the threshold. </div><div><br /></div><div>What do you think</div>","created":"2024-10-30T05:07:09Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2vf06wlykg1b6","updated":"2024-10-30T05:07:09Z","config":{}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"same problem as you, stuck at 0.6998. funnily enough I implemented it wrong and had 75% and it passed auto grader so now I&#39;m trying to fix it ","created":"2024-10-30T09:28:21Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"id":"m2voc3kll28oq","updated":"2024-10-30T09:28:21Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Yeah I did the same thing once as well where I implemented it wrong and got a 73% passing rate.","created":"2024-10-30T16:17:22Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2w2y3jwsgf5q6","updated":"2024-10-30T16:17:22Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"How do you know that you implemented it wrongly? I used threshold of 0.10 and got 79%. Is that wrong?","created":"2024-10-30T16:57:13Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_2","children":[],"tag_good_arr":[],"id":"m2w4dcghg8l1ug","updated":"2024-10-30T16:57:13Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"one way would be using ideas from question 4 to help question 3 but that would defeat the purpose of them being separate questions.","created":"2024-10-30T17:13:26Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2w4y6xmvkc3wc","updated":"2024-10-30T17:13:26Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Noted. I have been getting Q4 wrong this whole time so I guess I might be doing it wrong. For Q3, do you loop over the validation data or the training data to build the model? If we use the validation data, do we use the new validation data (with 20,000 data points) or the initial validation data (10,000 data points)?","created":"2024-10-30T17:17:23Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_2","children":[],"tag_good_arr":[],"id":"m2w539twiqm52m","updated":"2024-10-30T17:17:23Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"By build the model I assume you mean where i reference the book read in my predictor. I use if the book has been read in the training data as that what the instructions say to do. In terms of creating my validation data I use all data to determine if a book has been read or not and add random non read book to the validation data. If I only use validation data to add non read books I get very bad results around 64%.","created":"2024-10-30T18:22:38Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m2w7f6yr30e54o","updated":"2024-10-30T18:22:38Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m2vdthls6e62sz","updated":"2024-10-30T18:22:38Z","config":{"editor":"rte"}}],"tag_good_arr":["m1fmuc1nxah1fd","l871grkwo481d2"],"no_answer":0,"id":"m2v6z4bica143e","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":5,"num_favorites":1,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731986436193,"default_anonymity":"no"},"error":null,"aid":"m3nw076c5q74v7"}