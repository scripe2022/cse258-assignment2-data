{"result":{"history_size":1,"folders":["hw1"],"nr":80,"data":{"embed_links":[]},"created":"2024-10-13T10:56:30Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m27gzyyvbyr538","v":"all","type":"create","when":"2024-10-13T10:56:30Z","uid_a":"a_0"},{"anon":"no","uid":"kfo0vtto1k321a","data":"m27npgt03qe11n","to":"m27gzyypgtb537","type":"i_answer","when":"2024-10-13T14:04:17Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Issue Loading Beer Dataset: Skipping Thousands of Lines due to JSON Errors","created":"2024-10-13T10:56:30Z","content":"<p>Hi everyone,</p>\n<p>I’m having trouble loading the <code>beer_50000.json</code> dataset for Homework 1. While my code can load the GoodReads dataset without any problems, I’m encountering <strong>many malformed lines</strong> when trying to load the beer dataset. </p>\n<h3><strong>Problem Details:</strong></h3>\n<ul><li>Out of 50,000 beer reviews, only ~17,734 are being successfully loaded.</li><li>I&#39;m seeing errors like:<br />Skipping malformed line 49999: Expecting &#39;,&#39; delimiter: line 1 column 142 (char 141)<br />Skipping malformed line 15: Expecting &#39;,&#39; delimiter: line 1 column 600 (char 599)<br />The dataset is loaded using Python’s <code>json</code> module, and I’ve also tried cleaning it by:\n<ol><li><strong>Replacing single quotes with double quotes</strong>.</li><li><strong>Encoding lines in UTF-8</strong>.</li><li><strong>Using the <code>jsonlines</code> library as a fallback</strong>, but many lines are still skipped.</li></ol>\n<ul><li>Could the JSON file itself be corrupted, or is there another approach I should try to handle this data more effectively?</li><li>If this is a known issue with the dataset, would it be possible to get a <strong>corrected version</strong> of the file or some <strong>tips</strong> on parsing it?</li></ul>\n<p>Any insights or help would be greatly appreciated! I want to ensure I’m not missing critical reviews for my analysis.</p>\n<p>Thank you!</p>\n</li></ul>\n<p></p>"}],"type":"question","tags":["hw1","student"],"tag_good":[{"role":"student","name":"Elaine Sun","endorser":{},"admin":false,"photo":null,"id":"l7uh7v3kyqm28d","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":256,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-13T14:04:17Z","bucket_order":3,"tag_endorse":[{"role":"professor","name":"Julian McAuley","endorser":{},"admin":true,"photo":null,"id":"icbjgije2033xe","photo_url":null,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"kfo0vtto1k321a","subject":"","created":"2024-10-13T14:04:17Z","content":"<md>You can use the codes in the stub file to correctly load the dataset. And it is expected that only a portion of examples in the dataset is valid.</md>"}],"type":"i_answer","tag_endorse_arr":["icbjgije2033xe"],"children":[],"id":"m27npgsu8tb11m","config":{"editor":"md"},"is_tag_endorse":false}],"tag_good_arr":["l7uh7v3kyqm28d"],"no_answer":0,"id":"m27gzyypgtb537","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731986328669,"default_anonymity":"no"},"error":null,"aid":"m3nvxw7mnn5500"}