{"result":{"history_size":1,"folders":["hw1"],"nr":87,"data":{"embed_links":[]},"created":"2024-10-15T18:16:20Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2arlayae3vx1","v":"all","type":"create","when":"2024-10-15T18:16:20Z","uid_a":"a_0"},{"anon":"no","uid":"lml4g5v8hzj1lc","data":"m2ati8a9rp03ht","to":"m2arlay31bhx0","type":"i_answer","when":"2024-10-15T19:09:55Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Questions about hw1","created":"2024-10-15T18:16:20Z","content":"<p>A few questions I had:</p>\n<p></p>\n<p>1. Do we need to use random_state in when we split our data into training and testing sets?</p>\n<p></p>\n<p>2. In @37, the TA/instructor instructed that we can use np.lingalg for linear regression. In the class notebook, there is a different way to train the model using sklearn. Are any of the methods okay? Both of them give the same answers.</p>"}],"type":"question","tags":["hw1","student"],"tag_good":[],"unique_views":271,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-15T19:09:55Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lml4g5v8hzj1lc","subject":"","created":"2024-10-15T19:09:55Z","content":"<md>1. I would split your training/test set by using array indexing (like dataset[:int(.8*len)], rather than using a library to match the autograder.\n\n2. I would use sklearn LinearRegression</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2ati8a2oi93hs","config":{"editor":"md"},"is_tag_endorse":false}],"tag_good_arr":[],"no_answer":0,"id":"m2arlay31bhx0","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731986336229,"default_anonymity":"no"},"error":null,"aid":"m3nvy21n8o26m2"}