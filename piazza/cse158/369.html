{"result":{"history_size":1,"folders":["assignment1"],"nr":369,"data":{"embed_links":[]},"created":"2024-11-16T23:55:43Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m3ktt0pbzo1ei","v":"all","type":"create","when":"2024-11-16T23:55:43Z","uid_a":"a_0"},{"anon":"no","uid":"icbjgije2033xe","data":"m3kvhyt485r4o3","to":"m3ktt0p4kny1eh","type":"i_answer","when":"2024-11-17T00:43:07Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Conceptual question about Assignment 1","created":"2024-11-16T23:55:43Z","content":"I&#39;m a bit confused on the point of the assignment. As far as I understand we want to train models to predict the unseen data as accurately as possible. However we are being encouraged to meticulously tune hyperparameters to perform well on the seen tests, when most of the points are the unseen tests. Isn&#39;t this in essence bad practice as by continuously tuning hyperparameters we are making assumptions about the unseen data and overfitting? Are we just assuming the hidden data is extremely similar to the seen test data? Maybe someone can clarify because it seems to me that it would not generalize as well to the unseen data the more we tune to the seen data."}],"type":"question","tags":["assignment1","student"],"tag_good":[{"role":"student","name":"Yunhao Jiang","endorser":{},"admin":false,"photo":null,"id":"m182ypevmgf41p","photo_url":null,"us":false,"facebook_id":null},{"role":"student","name":"Sara Bailouni","endorser":{},"admin":false,"photo":null,"id":"krtky3jb86i14i","photo_url":null,"us":false,"facebook_id":null}],"unique_views":205,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-17T00:43:06Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Arturo Ballesteros-Ontiveros","endorser":{},"admin":false,"photo":null,"id":"ktvosufbfm55n6","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Zachary Perry","endorser":{},"admin":false,"photo":null,"id":"ktvoo3jdotzo6","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Han Hoang","endorser":{},"admin":false,"photo":null,"id":"l855zhvzhur6sa","photo_url":null,"published":true,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"icbjgije2033xe","subject":"","created":"2024-11-17T00:43:07Z","content":"I think your points are all valid -- you should not overly tune your model to the seen portion, because you want it to work well for the unseen portion. But in practice I doubt there&#39;s too much room for error here -- the test data is quite big (~10k samples), so you&#39;re unlikely to have bad performance on just one half of it. And I assume nobody has more than a few hyperparameters they&#39;re tuning -- so it should be pretty hard to &#34;overfit&#34; to the test set."}],"type":"i_answer","tag_endorse_arr":["ktvosufbfm55n6","ktvoo3jdotzo6","l855zhvzhur6sa"],"children":[],"id":"m3kvhysyf4c4o2","config":{"editor":"rte"},"is_tag_endorse":false}],"tag_good_arr":["m182ypevmgf41p","krtky3jb86i14i"],"no_answer":0,"id":"m3ktt0p4kny1eh","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":2,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731986687033,"default_anonymity":"no"},"error":null,"aid":"m3nw5kq4bi9dz"}