{"result":{"history_size":1,"folders":["pa1"],"nr":100,"data":{"embed_links":[]},"created":"2024-10-15T00:26:59Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m29pe480w0k453","v":"all","type":"create","when":"2024-10-15T00:26:59Z","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m29qtrvecr46w9","to":"m29pe47rxth451","type":"i_answer","when":"2024-10-15T01:07:09Z"},{"anon":"stud","to":"m29pe47rxth451","type":"followup","when":"2024-10-15T01:32:18Z","cid":"m29rq4exv2b2it","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m29pe47rxth451","type":"feedback","when":"2024-10-15T02:03:10Z","cid":"m29stsxtpd96jl"},{"anon":"stud","to":"m29pe47rxth451","type":"feedback","when":"2024-10-15T02:23:38Z","cid":"m29tk4ruoan3og","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m29pe47rxth451","type":"feedback","when":"2024-10-15T02:29:07Z","cid":"m29tr6xoyh03oi"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"BPE forward function","created":"2024-10-15T00:26:59Z","content":"Is my understanding right that in the forward function, if our batch size is 16, that means that we will have 16 sentences? If so, then we take each word from each sentence and get the respective random embedding array and average it based on each sentence? If so, then my dimensions come out to be [16,1,300] which shouldn&#39;t be the case right? Can you pls correct me if my understanding is wrong ?"}],"type":"question","tags":["pa1","student"],"tag_good":[],"unique_views":137,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-15T01:07:09Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-15T01:07:09Z","content":"That sounds reasonable, but could you explain where the <code>1</code> comes from in <code>[16, 1, 300]</code>?"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m29qtrv8x3e6w7","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"Yeah because you are averaging each word in a sentence. Each word has a dimension of [1,300]. Since there are 16 sentences, then it comes out to be [16,1,300]","created":"2024-10-15T01:32:18Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"I don’t quite understand why each word has an embedding dimension of [1, 300]—why not just [300]? Btw, I believe there are several ways to implement this, and it could be an implementation choice. So if your model is running successfully, that’s great!","created":"2024-10-15T02:03:10Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":[],"id":"m29stsxtpd96jl","updated":"2024-10-15T02:03:10Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Do we get one average for the entire batch or 16 different averages? I guess that part doesn&#39;t make sense to me.","created":"2024-10-15T02:23:38Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m29tk4ruoan3og","updated":"2024-10-15T02:23:38Z","config":{"editor":"rte"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<p>You get 16 different averages, one for each sentence in the batch. The idea is that for each sentence, you take the word embeddings, average them together, and produce a single embedding for that sentence. So, if your batch size is 16, you&#39;ll have 16 separate average embeddings, each with a shape of [300], resulting in a tensor of shape [16, 300].</p>\n<p></p>\n<p>For more details, please refer to the DAN <a href=\"https://people.cs.umass.edu/~miyyer/pubs/2015_acl_dan.pdf\" target=\"_blank\" rel=\"noopener noreferrer\">paper</a>.</p>","created":"2024-10-15T02:29:07Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":[],"id":"m29tr6xoyh03oi","updated":"2024-10-15T02:29:07Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m29rq4exv2b2it","updated":"2024-10-15T02:29:07Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m29pe47rxth451","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990104643,"default_anonymity":"no"},"error":null,"aid":"m3ny6trpwus266"}