{"result":{"history_size":2,"folders":["pa1"],"nr":45,"data":{"embed_links":[]},"created":"2024-10-11T03:26:29Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m2461k2guk41m1","v":"all","type":"create","when":"2024-10-11T03:26:29Z","uid_a":"a_0"},{"anon":"stud","data":"m2463l64ygb4ia","v":"all","type":"update","when":"2024-10-11T03:28:04Z","uid_a":"a_0"},{"anon":"no","uid":"lmr7yhnqdjb6ul","data":"m2490pupezk5oj","to":"m2461k29lbe1m0","type":"i_answer","when":"2024-10-11T04:49:49Z"},{"anon":"stud","to":"m2461k29lbe1m0","type":"followup","when":"2024-10-11T04:53:40Z","cid":"m2495ob1afr5db","uid_a":"a_0"},{"anon":"no","uid":"lmr7yhnqdjb6ul","to":"m2461k29lbe1m0","type":"feedback","when":"2024-10-11T04:56:24Z","cid":"m24996hl6kg5v"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Seeding","created":"2024-10-11T03:28:04Z","content":"<p>I would like to understand why seeding the embedded layer is technically not cheating the program. If the DAN model was an accurate model for sentiment analysis, shouldn&#39;t it work for any seed? For example for one of the seeds, my program returns a 50% accuracy, while with another seed it passes the given threshold in the PA. It seems that if we tested for a different dev.txt, the seed would not work. Can someone explain how this for me as well as how this works in the industry setting as well?</p>\n<p></p>\n<p>Additionally, when I test my program, I expected my dev accuracy to go up for every epoch, however, it stays relatively the same. Is this normal behavior? </p>"},{"anon":"stud","uid_a":"a_0","subject":"Seeding","created":"2024-10-11T03:26:29Z","content":"I would like to understand why seeding the embedded layer is technically not cheating the program. If the DAN model was an accurate model for sentiment analysis, shouldn&#39;t it work for any seed? For example for one of the seeds, my program returns a 50% accuracy, while with another seed it passes the given threshold in the PA. It seems that if we tested for a different dev.txt, the seed would not work. Can someone explain how this for me as well as how this works in the industry setting as well? "}],"type":"question","tags":["pa1","student"],"tag_good":[{"role":"student","name":"Rahul Sharma Nemmani","endorser":{},"admin":false,"photo":null,"id":"jml95ci0otv4w9","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Yuhang Jiang","endorser":{},"admin":false,"photo":null,"id":"l7uh0aen7ms4bp","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":178,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-11T04:49:49Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lmr7yhnqdjb6ul","subject":"","created":"2024-10-11T04:49:49Z","content":"<p>For the first question, the embedding layer&#39;s weights are randomly initialized at the beginning of training. If we get a bad initialization for the embedding, the embedding trained will probably get stuck into some local minima, which leads to low accuracy. This is a normal case, especially with simpler models like DAN, which can be quite sensitive to initialization. In industry settings, probably a way of solving this will be to train multiple models, and find one that performs the best on the dev, then apply that model.</p>\n<p></p>\n<p>For the second question, it is normal for the dev accuracy to stay relatively the same or even go down a bit after some point. This comes from the model overfitting the training data, which might contain some noise.</p>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2490puhud35oi","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"If this is the case that the initialized random values matter, how do we know for certain that our implementation is correct? ","created":"2024-10-11T04:53:40Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"If you find some of the random seeds can lead you to a pass of the accuracy threshold, the implementation should be correct. You can explore some methods to make it more stable, or just report the times when you get over 77% accuracy and explain the reason you think that leads to the 50% accuracy sometimes.","created":"2024-10-11T04:56:24Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"lmr7yhnqdjb6ul","children":[],"tag_good_arr":[],"id":"m24996hl6kg5v","updated":"2024-10-11T04:56:24Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m2495ob1afr5db","updated":"2024-10-11T04:56:24Z","config":{"editor":"rte"}}],"tag_good_arr":["jml95ci0otv4w9","l7uh0aen7ms4bp"],"no_answer":0,"id":"m2461k29lbe1m0","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":2,"my_favorite":false,"is_bookmarked":false,"is_tag_good":true,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990047794,"default_anonymity":"no"},"error":null,"aid":"m3ny5lwms7f40r"}