{"result":{"history_size":1,"folders":["pa2"],"nr":374,"data":{"embed_links":[]},"created":"2024-11-04T06:33:17Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m32na83il0uga","v":"all","type":"create","when":"2024-11-04T06:33:17Z","uid_a":"a_0"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m33bnlf4m1i3qw","to":"m32na83acl2g9","type":"i_answer","when":"2024-11-04T17:55:32Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Part 2.1 feedforward","created":"2024-11-04T06:33:17Z","content":"<p>The requirement says: Your feedforward hidden dimensionality is 100, and the activation function is ReLU.</p>\n<p>Is it referring to the feedforward in the transformer or the linear layers after the transformer?</p>"}],"type":"question","tags":["pa2","student"],"tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":109,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-04T17:55:32Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-11-04T17:55:32Z","content":"<md>It refers to the feedforward in the transformer.</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m33bnley3q83qv","config":{"editor":"md"},"is_tag_endorse":false}],"tag_good_arr":["kfsi52ar6572xo"],"no_answer":0,"id":"m32na83acl2g9","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":2,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990376942,"default_anonymity":"no"},"error":null,"aid":"m3nycnvk7783gt"}