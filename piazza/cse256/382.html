{"result":{"history_size":1,"folders":["pa2"],"nr":382,"data":{"embed_links":[]},"created":"2024-11-04T23:10:33Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"no","uid":"m182yxkiqd84os","data":"m33mwpu0yuc7eg","v":"all","type":"create","when":"2024-11-04T23:10:33Z"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m33o8riqz5y15q","to":"m33mwpttqcg7ee","type":"i_answer","when":"2024-11-04T23:47:55Z"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m33o8wk3jp61ds","type":"i_answer_update","when":"2024-11-04T23:48:01Z"},{"anon":"no","uid":"m182yxkiqd84os","to":"m33mwpttqcg7ee","type":"followup","when":"2024-11-05T00:26:32Z","cid":"m33pmf663kb5am"}],"bucket_name":"Today","history":[{"anon":"no","uid":"m182yxkiqd84os","subject":"perplexity keeps going up","created":"2024-11-04T23:10:33Z","content":"I used the same dataloader for test and train txt, my training perplexity is going down to &lt; 10, but my test perplexity go up. from 500s to &gt;10000s, and I print out the prediction for test data, and there is no pattern of learning at all. What could be the issue? and my architecture for decoder is adding a mask attention and in the end, projecting the shape to vocab_size. Where could be wrong?"}],"type":"question","tags":["pa2","student"],"tag_good":[],"unique_views":129,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-11-04T23:47:55Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-11-04T23:48:01Z","content":"<md>\"my training perplexity is going down to < 10\". -> your causal masking implementation is wrong. \n\nPlease take a look your masking is correctly working. Correct implementation should show the plots something like this: @299</md>"},{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-11-04T23:47:55Z","content":"<md>\"my training perplexity is going down to < 10\". -> your causal masking implementation is wrong. Please take a look your masking is correctly working. Correct implementation should show the plots something like this: @299</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m33o8rijjn115p","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"no","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fm182yxkiqd84os%2F13a22e15b029a13a604605ca3c42ce2ea32195d690b846fe9ef2b493f1255428%2Fimage.png\" alt=\"image.pngNaN\" width=\"620\" height=\"520\" /></p>\n<p>but my attention map looks like this, so I think I add mask right?</p>\n<p></p>","created":"2024-11-05T00:26:32Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid":"m182yxkiqd84os","children":[],"tag_good_arr":[],"no_answer":1,"id":"m33pmf663kb5am","updated":"2024-11-05T00:26:52Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m33mwpttqcg7ee","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990385828,"default_anonymity":"no"},"error":null,"aid":"m3nycuqeo545cv"}