{"result":{"history_size":1,"folders":["pa2"],"nr":303,"data":{"embed_links":[]},"created":"2024-10-30T09:43:19Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2vovcpsesy2du","v":"all","type":"create","when":"2024-10-30T09:43:19Z","uid_a":"a_0"},{"anon":"no","uid":"jcl6zbf3r2f52p","data":"m2vvo1xytfk4yv","to":"m2vovcpmuia2ds","type":"i_answer","when":"2024-10-30T12:53:36Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"def load_texts for Tokenization error ?","created":"2024-10-30T09:43:19Z","content":"The def load_texts function given in the PA2 Zip file reads all the files within the &#34;speechesdataset&#34; folder with the exception of &#34;test&#34; files. Although there are 2 type of train files here one for Part 1 and Part 2 that is CLS and LM tasks. Using the code given in the PA 2 Zip file the tokenizer must tokenize on both these files but since these tasks are separate shouldn&#39;t we tokenize them separately ? Since the CLS file would have parts of speech from the test files for the LM task like Hbush , Obama and Wbush. This would lead to data leakage and extra vocabulary size and would then affect the perplexity. Could this be checked once again so that if so , the perplexities mentioned within the PDF should be apt or not ? "}],"type":"question","tags":["pa2","student"],"tag_good":[],"unique_views":120,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-30T12:53:36Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Abhay Lal","endorser":{},"admin":false,"photo":null,"id":"m182yj0uy1c3ja","photo_url":null,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"jcl6zbf3r2f52p","subject":"","created":"2024-10-30T12:53:36Z","content":"The tokenizer provides a consistent mapping from tokens to IDs (encode) and back (decode).  It does not cause any data leakage. The vocabulary also determines what counts as UNK. There is no need to modify the tokenization part."}],"type":"i_answer","tag_endorse_arr":["m182yj0uy1c3ja"],"children":[],"id":"m2vvo1xsmei4yu","config":{"editor":"rte"},"is_tag_endorse":false}],"tag_good_arr":[],"no_answer":0,"id":"m2vovcpmuia2ds","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990308459,"default_anonymity":"no"},"error":null,"aid":"m3nyb71ad1917a"}