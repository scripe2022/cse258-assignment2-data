{"result":{"history_size":1,"folders":["pa1"],"nr":154,"data":{"embed_links":[]},"created":"2024-10-17T05:51:51Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2cvvld5d003xb","v":"all","type":"create","when":"2024-10-17T05:51:51Z","uid_a":"a_0"},{"anon":"no","uid":"m182yt8a22e4cr","data":"m2cwft6ran075i","to":"m2cvvlcx3do3xa","type":"s_answer","when":"2024-10-17T06:07:34Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Runtime Very Long for Question 1A","created":"2024-10-17T05:51:51Z","content":"<p>The runtime of my 1A model is taking a very long time. This started once I added the embedding layer and the summation layer to the forward function. When I computed the embeddings and summations outside of the forward function, it completed in under 2 minutes.</p>\n<p></p>\n<p>Has anyone else had this issue and found a common solution? It&#39;s unclear whether this is an issue with my architecture or my code.Â </p>"}],"type":"question","tags":["pa1","student"],"tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":113,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-17T06:07:34Z","bucket_order":3,"tag_endorse":[{"role":"ta","name":"Po-Chun Wu","endorser":{},"admin":true,"photo":null,"id":"ln0md59uz9w3kd","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Connor Gag","endorser":{},"admin":false,"photo":null,"id":"m182ypcc1bq41j","photo_url":null,"published":true,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"m182yt8a22e4cr","subject":"","created":"2024-10-17T06:07:34Z","content":"<md>Are you manually converting the word indices to their corresponding embeddings (e.g., with a for-loop)? If so, that could explain your slow runtime. I don't know how exactly your implementation works, though, so I can't know for sure which part of your code is too inefficient.\n\nPersonally, I have my embedding layer as an `Embedding` object that I just pass the input vector `x` into, so my DAN model doesn't really have runtime issues, at least not with the default hidden layer size and layer count.</md>"}],"type":"s_answer","tag_endorse_arr":["ln0md59uz9w3kd","m182ypcc1bq41j"],"children":[],"id":"m2cwft6kim075g","config":{"editor":"md"},"is_tag_endorse":false}],"tag_good_arr":["kfsi52ar6572xo"],"no_answer":0,"id":"m2cvvlcx3do3xa","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990166636,"default_anonymity":"no"},"error":null,"aid":"m3ny85ls16e7h3"}