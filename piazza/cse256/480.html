{"result":{"history_size":1,"folders":["pa3"],"nr":480,"data":{"embed_links":[]},"created":"2024-11-16T00:22:33Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m3jfbooxolc5hq","v":"all","type":"create","when":"2024-11-16T00:22:33Z","uid_a":"a_0"},{"anon":"no","uid":"lmr7yhnqdjb6ul","data":"m3jfd2nrovw2t1","to":"m3jfbooos8g5hp","type":"i_answer","when":"2024-11-16T00:23:38Z"},{"anon":"stud","to":"m3jfbooos8g5hp","type":"followup","when":"2024-11-16T00:28:59Z","cid":"m3jfjxwuen94nj","uid_a":"a_0"},{"anon":"no","uid":"lmr7yhnqdjb6ul","to":"m3jfbooos8g5hp","type":"feedback","when":"2024-11-16T00:34:03Z","cid":"m3jfqgqgh8t5pw"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Do we need to tokenize and embed the documents before the function call?","created":"2024-11-16T00:22:33Z","content":"It seems that the provided code doesn&#39;t include tokenized and embedded documents. Do we need to tokenize and embed all the documents before the function call?"}],"type":"question","tags":["pa3","student"],"tag_good":[],"unique_views":119,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-16T00:23:38Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lmr7yhnqdjb6ul","subject":"","created":"2024-11-16T00:23:38Z","content":"Yes, that&#39;s part of the work you need to do on Q5."}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m3jfd2nkc6a2t0","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<p>On Colab, I got this when trying to store all of the embedded documents:</p>\n<p></p>\n<p>Your session crashed after using all available RAM.</p>\n<p></p>\n<p>I guess I can only embed the document during the function call.</p>","created":"2024-11-16T00:28:59Z","bucket_order":6,"bucket_name":"Last week","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<p>Sorry for missing the point &#34;before the function call.&#34;</p>\n<p></p>\n<p>Yes, you are right. Since we are only querying one user query, it will be better to do the embedding for the 15 documents retrieved by the Bi-Encoder <strong>in the function</strong> &#34;rank_documents_finegrained_interactions.&#34;Â </p>","created":"2024-11-16T00:34:03Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid":"lmr7yhnqdjb6ul","children":[],"tag_good_arr":["kfsi52ar6572xo"],"id":"m3jfqgqgh8t5pw","updated":"2024-11-18T21:47:36Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m3jfjxwuen94nj","updated":"2024-11-16T00:34:03Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m3jfbooos8g5hp","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990474498,"default_anonymity":"no"},"error":null,"aid":"m3nyer5i9fs5kh"}