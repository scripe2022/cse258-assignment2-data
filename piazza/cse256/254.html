{"result":{"history_size":1,"folders":["pa2"],"nr":254,"data":{"embed_links":[]},"created":"2024-10-25T21:57:34Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"no","uid":"k136zl2fvk36eg","data":"m2p9wcfxdq120i","v":"all","type":"create","when":"2024-10-25T21:57:34Z"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m2pogzria6r34h","to":"m2p9wcfp7i720h","type":"i_answer","when":"2024-10-26T04:45:32Z"},{"anon":"no","uid":"lmpga1m6ftd62m","data":"m2pr2aqt1xg12l","type":"i_answer_update","when":"2024-10-26T05:58:06Z"},{"anon":"no","uid":"k136zl2fvk36eg","to":"m2p9wcfp7i720h","type":"followup","when":"2024-10-26T06:10:41Z","cid":"m2prihbhz9y41y"},{"anon":"no","uid":"ku2mpmjms7n645","to":"m2p9wcfp7i720h","type":"feedback","when":"2024-10-26T21:42:55Z","cid":"m2qotcdgtiu6vs"}],"bucket_name":"Today","history":[{"anon":"no","uid":"k136zl2fvk36eg","subject":"Part 2 Decoder Masked Attention","created":"2024-10-25T21:57:34Z","content":"<p>During Training for the decoder, for a given sample sentence in your batch, is our decoder supposed to take in the first block_size-1 words into the transformer block and predict the words 2-block_size&#43;1 using mask to prevent cheating?</p>\n<p></p>\n<p>And then during testing we do not need the mask since we are just predicting the last word given the first block_size-1 words?</p>\n<p></p>\n<p></p>"}],"type":"question","tags":["pa2","student"],"tag_good":[],"unique_views":129,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-10-26T04:45:32Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lmpga1m6ftd62m","subject":"","created":"2024-10-26T05:58:06Z","content":"<md>The format of input and output of the decoder is provided in the LanguageModelingDatasets class. See `__getitem__` function.\n\nMask is (32 x 32) an upper triangular matrix, use `torch.tril`  or `torch.triu`</md>"},{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-10-26T04:45:32Z","content":"<md>The format of input and output of the decoder is provided in the LanguageModelingDatasets class. See `__getitem__` function.\n\nMask is (32 x 32) an upper triangular matrix, use `torch.tril`  or `torch.triu`</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2pogzr9muz34f","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"no","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<p>I see that the getitem function returns the word chunk shifted by 1, so then does that mean our feedfoward layer needs to output a (batch, sequence length, vocab_size) shape vector? And we treat it like a classification problem for each word?</p>\n<p></p>\n<p>And then testing would be the same thing?</p>\n<p></p>\n<p>Then what about during inference if we want to generate words autoregressively, do we still to mask in that case?Â </p>","created":"2024-10-26T06:10:41Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid":"k136zl2fvk36eg","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>does that mean our feedfoward layer needs to output a (batch, sequence length, vocab\\_size) => yes\n\nwe don't need a mask at inference time. the model generates one token at each step and then feeds the generated token to the input for next generation step.</md>","created":"2024-10-26T21:42:55Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"ku2mpmjms7n645","children":[],"tag_good_arr":[],"id":"m2qotcdgtiu6vs","updated":"2024-10-26T21:42:55Z","config":{"editor":"md"}}],"tag_good_arr":[],"no_answer":1,"id":"m2prihbhz9y41y","updated":"2024-10-26T21:42:55Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m2p9wcfp7i720h","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990262950,"default_anonymity":"no"},"error":null,"aid":"m3nya7x8ndb4ub"}