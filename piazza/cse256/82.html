{"result":{"history_size":3,"folders":["pa1"],"nr":82,"data":{"embed_links":[]},"created":"2024-10-14T03:22:46Z","bucket_order":3,"no_answer_followup":2,"change_log":[{"anon":"stud","data":"m28g8c13c1p2b9","v":"private","type":"create","when":"2024-10-14T03:22:46Z","uid_a":"a_0"},{"anon":"stud","data":"m28gbxwzjxq74y","v":"private","type":"update","when":"2024-10-14T03:25:35Z","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m28hstxs6ht33h","to":"m28g8c0vzi52b7","type":"i_answer","when":"2024-10-14T04:06:42Z"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m28g8c0vzi52b7","type":"followup","when":"2024-10-14T04:14:16Z","cid":"m28i2jp9uvy2kn"},{"anon":"stud","data":"m28i5l1jw2r4ig","v":"all","type":"update","when":"2024-10-14T04:16:37Z","uid_a":"a_0"},{"anon":"stud","to":"m28g8c0vzi52b7","type":"followup","when":"2024-10-14T04:23:43Z","cid":"m28iep3nrgxoo","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m28g8c0vzi52b7","type":"feedback","when":"2024-10-14T04:27:21Z","cid":"m28ijdkl3l635r"},{"anon":"stud","to":"m28g8c0vzi52b7","type":"feedback","when":"2024-10-14T08:43:50Z","cid":"m28rp86kl1f2uh","uid_a":"a_1"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m28g8c0vzi52b7","type":"feedback","when":"2024-10-14T14:40:32Z","cid":"m294fxtwv5f5h"},{"anon":"stud","to":"m28g8c0vzi52b7","type":"feedback","when":"2024-10-14T18:00:00Z","cid":"m29bkgmdz3asw","uid_a":"a_1"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m28g8c0vzi52b7","type":"feedback","when":"2024-10-14T20:04:20Z","cid":"m29g0cg7nz8404"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Sub word vocabulary","created":"2024-10-14T04:16:37Z","content":"I have developed my subword vocabulary. I am not sure what I am supposed to do in the __getitem__ function for the BPE. What are the indices I am supposed to return here? Can someone provide an example of how to approach this?"},{"anon":"stud","uid_a":"a_0","subject":"Sub word vocabulary","created":"2024-10-14T03:25:35Z","content":"I have developed my subword vocabulary. I am not sure what I am supposed to do in the __getitem__ function for the BPE. What are the indices I am supposed to return here? Can someone provide an example of how to approach this?"},{"anon":"stud","uid_a":"a_0","subject":"Sub word vocabulary","created":"2024-10-14T03:22:46Z","content":"I have developed my subword vocabulary. I am not sure what I am supposed to do in the __getitem__ function. What are the indices I am supposed to return here? Can someone provide an example of how to approach this?"}],"type":"question","tags":["pa1","student"],"tag_good":[{"role":"student","name":"Rahul Sharma Nemmani","endorser":{},"admin":false,"photo":null,"id":"jml95ci0otv4w9","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":172,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-14T04:06:42Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-14T04:06:42Z","content":"<p>After applying BPE tokenization, each word in the input will be split into subword units, which should be mapped to indices based on your subword vocabulary.</p>\n<p>For example, with the word &#34;natural&#34;:</p>\n<ul><li><strong>Word tokenization (Part 1)</strong>: The entire word &#34;natural&#34; would be treated as a single token.</li><li><strong>Subword tokenization (Part 2)</strong>: The word &#34;natural&#34; MIGHT be split into smaller units like &#34;nat&#34;, &#34;ur&#34;, and &#34;al&#34;, each corresponding to a unique subword index in your vocabulary.</li></ul>"}],"type":"i_answer","tag_endorse_arr":["kfsi52ar6572xo"],"children":[],"id":"m28hstxngd633g","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"no","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<p>Also, would you mind making this post public instead of private (you can choose to remain anonymous to your classmates)? Others may have similar questions, and it could be helpful for them as well. Thanks!</p>\n<p>Please only send us private messages when personal information is shared.</p>","created":"2024-10-14T04:14:16Z","bucket_order":5,"bucket_name":"This week","type":"followup","tag_good":[],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":[],"no_answer":1,"id":"m28i2jp9uvy2kn","updated":"2024-10-14T04:14:16Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"Do I have to do any sort of padding to this?","created":"2024-10-14T04:23:42Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"As long as the sentences in a batch have different lengths (i.e., number of tokens), padding is required to ensure that all sequences in a batch are of the same length.","created":"2024-10-14T04:27:21Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":["kfsi52ar6572xo"],"id":"m28ijdkl3l635r","updated":"2024-10-18T05:03:02Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Wouldn&#39;t the __getitem__ function for BPE be indexed by the corresponding index in the dataset? So this would instead return the corresponding sentence for the example. Then __getitem__ should return the tokenization for the entire sentence and not just a single word, right? I seem to have an issue with my BPE encoding, but I&#39;m pretty sure the encoding itself is working properly.<br /><br />To get the indices for a sentence, I just join the sentence with &#34; &#34;.join(sentence) and then run my encoder on the sentence string, does that sound correct?","created":"2024-10-14T08:43:50Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"id":"m28rp86kl1f2uh","updated":"2024-10-14T08:43:50Z","config":{"editor":"rte"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<p>Sounds reasonable.Â <br /><br />Btw depending on your implementation (edited: see @59), <code>&#34; &#34;.join(sentence)</code> may not work as expected with your BPE algorithm. Make sure you thoroughly understand how your BPE encoding handles subwords and spacing.</p>\n<p>A good debugging approach is to implement both encoding and decoding, and then verify if <code>decode(encode(x)) == x</code> to ensure the process is functioning correctly.<br /><br />Please let us know if you have further questions.<br /><br /></p>","created":"2024-10-14T14:40:32Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":["kfsi52ar6572xo"],"id":"m294fxtwv5f5h","updated":"2024-10-18T05:03:56Z","config":{"editor":"rte"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"I have implemented decode and encode, and verified that decode(encode(x)) == x. But, I&#39;m still only getting around 60% accuracy. I&#39;ve tried increasing the size of my vocabulary but that doesn&#39;t seem to affect the accuracy (tried with 500 and 7500 vocab size), but this just took longer and I had maybe 2-3% improvement.","created":"2024-10-14T18:00:00Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"id":"m29bkgmdz3asw","updated":"2024-10-14T18:00:00Z","config":{"editor":"rte"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<p>You might want to double-check your implementation. Try printing out some intermediate values (e.g., input to the forward function, embeddings, average vectors, layer outputs) to see if they align with your expectations. This may help you spot any issues.</p>\n<p></p>\n<p>Keep going, you&#39;re on the right track!</p>","created":"2024-10-14T20:04:20Z","bucket_order":5,"bucket_name":"This week","type":"feedback","tag_good":[],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":[],"id":"m29g0cg7nz8404","updated":"2024-10-14T20:04:20Z","config":{"editor":"rte"}}],"tag_good_arr":["kfsi52ar6572xo"],"no_answer":1,"id":"m28iep3nrgxoo","updated":"2024-10-18T05:03:05Z","config":{"editor":"rte"}}],"tag_good_arr":["jml95ci0otv4w9","kfsi52ar6572xo"],"no_answer":0,"id":"m28g8c0vzi52b7","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":1,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990085708,"default_anonymity":"no"},"error":null,"aid":"m3ny6f5tjch1la"}