{"result":{"history_size":1,"folders":["pa1"],"nr":129,"data":{"embed_links":[]},"created":"2024-10-16T03:09:05Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m2bamfjvbi165b","v":"all","type":"create","when":"2024-10-16T03:09:05Z","uid_a":"a_0"},{"anon":"no","uid":"ln0sa75cthl4zv","data":"m2bc8a9uvtg3nv","to":"m2bamfjohml65a","type":"i_answer","when":"2024-10-16T03:54:04Z"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m2bd2cl1sau3kx","type":"i_answer_update","when":"2024-10-16T04:17:27Z"},{"anon":"stud","to":"m2bamfjohml65a","type":"followup","when":"2024-10-17T15:01:35Z","cid":"m2dfikjmsyr3y9","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m2bamfjohml65a","type":"feedback","when":"2024-10-17T15:38:53Z","cid":"m2dgujc2ziz6gc"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Part 1)a) and 1)b) DAN model","created":"2024-10-16T03:09:05Z","content":"<div>After initializing the embedding layer from pretrained glove , should we use it for finding the embedding of each word in the examples?</div><div>Or are we supposed to manually find the embedding of each word using the get_embedding method of sentiments_data.py ? </div><div><br /></div><div>My code works both ways, but when doing part 1)b) my dev accuracy goes to about 50 percent. Will that be fine?</div>"}],"type":"question","tags":["pa1","student"],"tag_good":[],"unique_views":169,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-10-16T03:54:04Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-16T04:17:27Z","content":"You certainly need to get individual word embeddings for DAN. 50% is below our threshold. I encourage you to spend some more time understanding how your data and model are constructed.<div><br /></div><div>Edited:</div><div>@124</div>"},{"anon":"no","uid":"ln0sa75cthl4zv","subject":"","created":"2024-10-16T03:54:04Z","content":"You certainly need to get individual word embeddings for DAN. 50% is below our threshold. I encourage you to spend some more time understanding how your data and model are constructed."}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2bc8a9orcx3nu","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"I have now achieved a dev accuracy of 66% after following your instructions for part 1)b) random embedding initialization. <div>Will this accuracy be sufficient? </div>","created":"2024-10-17T15:01:35Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"Since I can&#39;t check your implementation right now, I cannot be certain if there are any implementation issues. But don&#39;t worry too much about the grading—partial credit will be given even if there are some flaws. Based on my experience, if your 1a achieves at least 77%, a correct implementation of 1b is likely to score higher than 70%. However, accuracy can vary due to multiple factors or hyperparameters. I suggest double-checking your code. If you still don’t find any bugs, trust your answers!","created":"2024-10-17T15:38:53Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":[],"id":"m2dgujc2ziz6gc","updated":"2024-10-17T15:38:53Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m2dfikjmsyr3y9","updated":"2024-10-17T15:38:53Z","config":{}}],"tag_good_arr":[],"no_answer":0,"id":"m2bamfjohml65a","config":{"has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990136280,"default_anonymity":"no"},"error":null,"aid":"m3ny7i6h5a964i"}