{"result":{"history_size":1,"folders":["pa1"],"nr":174,"data":{"embed_links":[]},"created":"2024-10-17T22:22:59Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2dva7bt5sc52k","v":"all","type":"create","when":"2024-10-17T22:22:59Z","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m2dzb0qle505ah","to":"m2dva7blwhu52j","type":"i_answer","when":"2024-10-18T00:15:35Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"BEP index mapping","created":"2024-10-17T22:22:59Z","content":"<p>Hi,</p>\n<p>Iâ€™m still not quite clear about the workflow of BPE. Once we have the subword dictionary, what should we do next? Should we encode both train.txt and dev.txt as UTF-8, and then compare each character with the subword vocabulary to get the index?</p>\n<p>I&#39;m confused about when to use the index for individual characters versus when to use the index for a merged subword. For example, if the original text is &#34;self-esteem&#34; and &#34;self-&#34; is in the subword vocabulary with an index of 999, how do I decide whether to map &#34;s&#34;, &#34;e&#34;, etc., to their individual UTF-8 indices, or use &#34;self-&#34; with the index 999? Since both &#34;s&#34;, &#34;e&#34;, etc., and &#34;self-&#34; are in the subword vocabulary, how should I make this decision?</p>"}],"type":"question","tags":["pa1","student"],"tag_good":[{"role":"student","name":"Soumi Chakraborty","endorser":{},"admin":false,"photo":null,"id":"hq7nezz1y222zb","photo_url":null,"us":false,"facebook_id":null},{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Ruilong Liu","endorser":{},"admin":false,"photo":null,"id":"m182yqr75sl457","photo_url":null,"us":false,"facebook_id":null}],"unique_views":131,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-18T00:15:35Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Hanyu Zhang","endorser":{},"admin":false,"photo":null,"id":"m182yvulg104ka","photo_url":null,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-18T00:15:35Z","content":"<p><a href=\"https://www.youtube.com/watch?v=zduSFxRajkE&amp;t=1430s\">https://www.youtube.com/watch?v=zduSFxRajkE&amp;t=1430s</a></p>\n<p><a href=\"https://www.youtube.com/watch?v=zduSFxRajkE&amp;t=2901s\" target=\"\" rel=\"noopener noreferrer\">(00:48:21)</a></p>\n<p></p>\n<p>Basically, to tokenize a new string, we pre-tokenize it, split it, and then apply all the merge rules learned. Please let us know if you still have any questions after watching the YouTube tutorial!</p>"}],"type":"i_answer","tag_endorse_arr":["m182yvulg104ka"],"children":[],"id":"m2dzb0qfwja5ag","config":{"editor":"rte"},"is_tag_endorse":false}],"tag_good_arr":["hq7nezz1y222zb","kfsi52ar6572xo","m182yqr75sl457"],"no_answer":0,"id":"m2dva7blwhu52j","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990186996,"default_anonymity":"no"},"error":null,"aid":"m3ny8lbcmt77dt"}