{"result":{"history_size":1,"folders":["pa1"],"nr":34,"data":{"embed_links":[]},"created":"2024-10-09T23:36:31Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m22idyfglpj48r","v":"all","type":"create","when":"2024-10-09T23:36:31Z","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m22j9am3gqe70n","to":"m22idyf7c4z48p","type":"i_answer","when":"2024-10-10T00:00:53Z"},{"anon":"stud","to":"m22idyf7c4z48p","type":"followup","when":"2024-10-10T02:19:01Z","cid":"m22o6xnbv2mb2","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","to":"m22idyf7c4z48p","type":"feedback","when":"2024-10-10T02:49:26Z","cid":"m22pa22oqcp3vj"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Do we need to pad the data?","created":"2024-10-09T23:36:31Z","content":"If the word embedding is not frozen, it will be trained, so the embedding cannot be in the dataset/dataloader. But if the embedding is in the model, since the input has varies size, do we need to pad the data such that each sentence is the same length?"}],"type":"question","tags":["pa1","student"],"tag_good":[],"unique_views":195,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-10T00:00:53Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-10T00:00:53Z","content":"<p>Yes, you need to pad the data.</p>\n<p></p>\n<p>Also, @29Â mentions a similar issue regarding padding and handling variable-length inputs, which might be helpful for you as well.</p>\n<p></p>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m22j9alvqtl70m","config":{"editor":"rte"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"DAN calculates the average of word embedding. Padding will make the average lower because of these 0s in the padding. Do we need to consider this or can we ignore it? If we want to address this issue, how do we calculate the mean without 0s using torch?","created":"2024-10-10T02:19:01Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Jinyi Wan","endorser":{},"admin":false,"photo":null,"id":"m182yqlxqmo44u","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<p>Good questions!</p>\n<p></p>\n<p>Ideally, we should calculate the average excluding the padding (zeros).</p>\n<p></p>\n<p>A simplified way to think about this is to calculate the average of the non-zero parts in a list.</p>\n<p>For example, given the list <kbd>[1,2,3,4,5,0,0,0]</kbd>, you would sum the non-zero values (1 &#43; 2 &#43; 3 &#43; 4 &#43; 5 = 15) and divide by the count of non-zero values (5), giving an average of 3.</p>\n<p></p>\n<p>In Python/PyTorch, you may consider using a &#34;mask&#34; to ignore the padding when calculating the mean.</p>\n<p></p>\n<p>However, if you average the embeddings including the padding parts, and still reach a dev accuracy of at least 77%, it&#39;s perfectly fine!</p>\n<p></p>\n<p>Also, please remember to briefly explain your approach in the write-up.</p>","created":"2024-10-10T02:49:26Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[{"role":"student","name":"Erica Cheng","endorser":{},"admin":false,"photo":null,"id":"m182ygrlgf83d9","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Yutian Shi","endorser":{},"admin":false,"photo":null,"id":"kfsi52ar6572xo","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Jinyi Wan","endorser":{},"admin":false,"photo":null,"id":"m182yqlxqmo44u","photo_url":null,"published":true,"us":false,"facebook_id":null}],"uid":"ln0md59uz9w3kd","children":[],"tag_good_arr":["m182ygrlgf83d9","kfsi52ar6572xo","m182yqlxqmo44u"],"id":"m22pa22oqcp3vj","updated":"2024-10-18T03:01:50Z","config":{"editor":"rte"}}],"tag_good_arr":["kfsi52ar6572xo","m182yqlxqmo44u"],"no_answer":1,"id":"m22o6xnbv2mb2","updated":"2024-10-18T03:01:28Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m22idyf7c4z48p","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990033900,"default_anonymity":"no"},"error":null,"aid":"m3ny5b6nn6o3ia"}