{"result":{"history_size":1,"folders":["pa2"],"nr":280,"data":{"embed_links":[]},"created":"2024-10-27T20:31:28Z","bucket_order":3,"no_answer_followup":1,"change_log":[{"anon":"stud","data":"m2s1pbqigm157t","v":"all","type":"create","when":"2024-10-27T20:31:28Z","uid_a":"a_0"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m2s30k5h2al4vj","to":"m2s1pbqaimp57s","type":"i_answer","when":"2024-10-27T21:08:12Z"},{"anon":"stud","to":"m2s1pbqaimp57s","type":"followup","when":"2024-10-27T21:17:07Z","cid":"m2s3c0limj12ju","uid_a":"a_0"},{"anon":"stud","uid_a":"a_1","to":"m2s1pbqaimp57s","type":"feedback","when":"2024-10-28T06:13:25Z","cid":"m2smhplh18l1p1"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Encoder","created":"2024-10-27T20:31:28Z","content":"<p>I am getting random results for the encoder portion of the assignment. Sometimes I get my percentages in the 80s and sometimes I get my percentages to be in the 50s. It seems inconsistent despite using both of the torch.manual_seed(seed) and the gpu seed function</p>\n<div>\n<div>torch.cuda.manual_seed_all(seed). Has anyone faced a similar issue and how did you go about debugging such instances. Thanks!</div>\n</div>\n<p></p>"}],"type":"question","tags":["pa2","student"],"tag_good":[{"role":"student","name":"Rahul Sharma Nemmani","endorser":{},"admin":false,"photo":null,"id":"jml95ci0otv4w9","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"William He","endorser":{},"admin":false,"photo":null,"id":"m182yx8vymi4ns","photo_url":null,"published":true,"us":false,"facebook_id":null},{"role":"student","name":"Melvyn Nam Qiang Tan","endorser":{"lfvsigi4w4t2pr":1686173608},"admin":false,"photo":null,"id":"kfo6ps0kgod3hx","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":157,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-27T21:08:12Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Erica Cheng","endorser":{},"admin":false,"photo":null,"id":"m182ygrlgf83d9","photo_url":null,"published":true,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-10-27T21:08:12Z","content":"<md>Hi, I think the place of LayerNorm can be a problem probably\n\nThere are two places to put the layer norm: pre-LN and post-LN, you can check out this [post](https://stackoverflow.com/questions/77864704/annotated-transformer-why-x-dropoutsublayerlayernormx) for details. \n\nPost-LN could lead to the instability, and pre-LN should work better.</md>"}],"type":"i_answer","tag_endorse_arr":["m182ygrlgf83d9"],"children":[],"id":"m2s30k5a9nr4vi","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"I have implemented pre-LN but it still gives me variable results. I&#39;m not sure how to debug this problem.","created":"2024-10-27T21:17:07Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"I was getting results similar to what you described in the original post. I added pre-LN and post-LN, and I am now getting consistent results.","created":"2024-10-28T06:13:25Z","bucket_order":3,"bucket_name":"Today","type":"feedback","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"id":"m2smhplh18l1p1","updated":"2024-10-28T06:13:25Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m2s3c0limj12ju","updated":"2024-10-28T06:13:25Z","config":{"editor":"rte"}}],"tag_good_arr":["jml95ci0otv4w9","m182yx8vymi4ns","kfo6ps0kgod3hx"],"no_answer":0,"id":"m2s1pbqaimp57s","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990286943,"default_anonymity":"no"},"error":null,"aid":"m3nyaqfmv971ja"}