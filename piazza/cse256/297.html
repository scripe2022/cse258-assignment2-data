{"result":{"history_size":1,"folders":["pa2"],"nr":297,"data":{"embed_links":[]},"created":"2024-10-29T18:38:06Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2usj85kfae27p","v":"all","type":"create","when":"2024-10-29T18:38:06Z","uid_a":"a_0"},{"anon":"no","uid":"lmpga1m6ftd62m","data":"m2utg40r3eh3uk","to":"m2usj85ey9627n","type":"i_answer","when":"2024-10-29T19:03:40Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Can we use scaled_dot_product_attention from pytorch?","created":"2024-10-29T18:38:06Z","content":"<md>Can we use torch.nn.functional.scaled_dot_product_attention from pytorch for matrix multiply? It will be more efficient than manually implementation.</md>"}],"type":"question","tags":["pa2","student"],"tag_good":[],"unique_views":131,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-10-29T19:03:40Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lmpga1m6ftd62m","subject":"","created":"2024-10-29T19:03:40Z","content":"You should try to implement all the necessary parts of the encoder and decoder from scratch.Using prepackaged solutions or libraries to do it will lead to a reduction in points.Â "}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2utg40k1qu3uj","config":{},"is_tag_endorse":false}],"tag_good_arr":[],"no_answer":0,"id":"m2usj85ey9627n","config":{"editor":"md","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":2,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990303398,"default_anonymity":"no"},"error":null,"aid":"m3nyb34r2a325p"}