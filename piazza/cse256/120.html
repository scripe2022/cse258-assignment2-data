{"result":{"history_size":1,"folders":["pa1"],"nr":120,"data":{"embed_links":[]},"created":"2024-10-15T20:51:44Z","bucket_order":3,"no_answer_followup":0,"change_log":[{"anon":"stud","data":"m2ax55iuiknco","v":"all","type":"create","when":"2024-10-15T20:51:44Z","uid_a":"a_0"},{"anon":"no","uid":"ln0md59uz9w3kd","data":"m2b4ylvijw3379","to":"m2ax55iko9cck","type":"i_answer","when":"2024-10-16T00:30:35Z"},{"anon":"no","uid":"lmpga1m6ftd62m","data":"m2bcso15e0e2vz","type":"i_answer_update","when":"2024-10-16T04:09:55Z"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Model weights randomly don&#39;t update","created":"2024-10-15T20:51:44Z","content":"I have an issue where my weights don&#39;t update, but this only occurs randomly. The same model on one run will train just fine, on the next run it won&#39;t update any weights and hang at 45% accuracy for all 100 epochs. <br /><br />From what I understand, this is an issue with backprop not pushing the gradient all the way through since I was originally having this problem with all my runs. Once I updated a type cast line to use the PyTorch recommended type casting, x = x.clone().to(torch.long) (instead of torch.tensor(x, dtype=torch.long)), it started working about 80% of the time. I have tried forcing by setting .requires_grad(True) but this doesn&#39;t work either.<br /><br />Any recommendations?"}],"type":"question","tags":["pa1","student"],"tag_good":[{"role":"student","name":"Tianyi Zheng","endorser":{},"admin":false,"photo":null,"id":"m182yt8a22e4cr","photo_url":null,"published":true,"us":false,"facebook_id":null}],"unique_views":122,"children":[{"history_size":2,"folders":[],"data":{"embed_links":[]},"created":"2024-10-16T00:30:35Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"lmpga1m6ftd62m","subject":"","created":"2024-10-16T04:09:55Z","content":"<p>There might be lots of reasons causing this.</p>\n<p></p>\n<p>Here are some recommendations:</p>\n<p>1. Check for In-place Operations: Ensure that no in-place operations are being used on tensors that require gradients, as they can sometimes cause issues with gradient flow.</p>\n<p>2. Set Seed: Try setting a seed for reproducibility to see if that changes the random behavior.</p>"},{"anon":"no","uid":"ln0md59uz9w3kd","subject":"","created":"2024-10-16T00:30:35Z","content":"<p>There might be lots of reasons causing this.</p>\n<p></p>\n<p>Here are some recommendations:</p>\n<p>1. Check for In-place Operations: Ensure that no in-place operations are being used on tensors that require gradients, as they can sometimes cause issues with gradient flow.</p>\n<p>2. Set Seed: Try setting a seed for reproducibility to see if that changes the random behavior.</p>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m2b4ylvdo00378","config":{"editor":"rte"},"is_tag_endorse":false}],"tag_good_arr":["m182yt8a22e4cr"],"no_answer":0,"id":"m2ax55iko9cck","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":3,"num_favorites":0,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990126161,"default_anonymity":"no"},"error":null,"aid":"m3ny7adfg3o30i"}