{"result":{"history_size":2,"folders":["pa2"],"nr":399,"data":{"embed_links":[]},"created":"2024-11-05T23:36:38Z","bucket_order":3,"no_answer_followup":2,"change_log":[{"anon":"stud","data":"m353a3x5p2p5af","v":"all","type":"create","when":"2024-11-05T23:36:38Z","uid_a":"a_0"},{"anon":"stud","data":"m353bvsgznq7my","v":"all","type":"update","when":"2024-11-05T23:38:01Z","uid_a":"a_0"},{"anon":"no","uid":"m182yt8a22e4cr","data":"m3551y83lr23r9","to":"m353a3wyt6p5ad","type":"s_answer","when":"2024-11-06T00:26:17Z"},{"anon":"stud","to":"m353a3wyt6p5ad","type":"followup","when":"2024-11-06T00:33:52Z","cid":"m355bpzkk32ur","uid_a":"a_0"},{"anon":"no","uid":"m182yt8a22e4cr","to":"m353a3wyt6p5ad","type":"feedback","when":"2024-11-06T00:41:56Z","cid":"m355m35y98y1sg"},{"anon":"stud","to":"m353a3wyt6p5ad","type":"feedback","when":"2024-11-06T00:48:43Z","cid":"m355uszvv8ab","uid_a":"a_0"},{"anon":"no","uid":"m182yt8a22e4cr","to":"m353a3wyt6p5ad","type":"feedback","when":"2024-11-06T01:08:16Z","cid":"m356jy53viu58n"},{"anon":"stud","to":"m353a3wyt6p5ad","type":"feedback","when":"2024-11-06T01:11:59Z","cid":"m356oqm41os71g","uid_a":"a_0"},{"anon":"no","uid":"ku2mpmjms7n645","data":"m35dh8a3bst1gy","to":"m353a3wyt6p5ad","type":"i_answer","when":"2024-11-06T04:22:06Z"},{"anon":"stud","uid_a":"a_1","to":"m353a3wyt6p5ad","type":"followup","when":"2024-11-06T18:09:09Z","cid":"m3670tgmodb7gd"}],"bucket_name":"Today","history":[{"anon":"stud","uid_a":"a_0","subject":"Attention map for part1","created":"2024-11-05T23:38:01Z","content":"<p>Hi,</p>\n<p>I wonder why the attention map for the encoder looks so messy. I used the first sentence in <code>train_CLS.tsv</code> for a sanity check, and the sum of each row is 1. My accuracy is also 80%, so I’m curious why the attention map still looks messy. Could you give me some advice?</p>\n<p></p>\n<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fm182yvulg104ka%2F711d41657036dfc9352c9c094b912f89f55986493baa76842f58ff6d26fc6dfc%2F_____20241105145223.png\" alt=\"\" /></p>"},{"anon":"stud","uid_a":"a_0","subject":"Attention map for part1","created":"2024-11-05T23:36:38Z","content":"<p>Hi,</p>\n<p>I wonder why the attention map for the encoder looks so messy. I used the first sentence in <code>train_CLS.tsv</code> for a sanity check, and the sum of each row is 1. My accuracy is also 80%, so I’m curious why the attention map still looks messy.</p>\n<p></p>\n<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fm182yvulg104ka%2F711d41657036dfc9352c9c094b912f89f55986493baa76842f58ff6d26fc6dfc%2F_____20241105145223.png\" alt=\"\" /></p>"}],"type":"question","tags":["pa2","student"],"tag_good":[],"unique_views":160,"children":[{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-06T00:26:17Z","bucket_order":3,"tag_endorse":[{"role":"student","name":"Sarvani Kunapareddy","endorser":{},"admin":false,"photo":"a108afd0-df22-4c82-a48b-4615ee8b0e26_200.jpg","id":"m182yor466x3zz","photo_url":"https://cdn-uploads.piazza.com/photos/m182yor466x3zz/a108afd0-df22-4c82-a48b-4615ee8b0e26_200.jpg","published":true,"us":false,"facebook_id":null}],"bucket_name":"Today","history":[{"anon":"no","uid":"m182yt8a22e4cr","subject":"","created":"2024-11-06T00:26:17Z","content":"<md>Are you running the sanity check before or after training the encoder?</md>"}],"type":"s_answer","tag_endorse_arr":["m182yor466x3zz"],"children":[],"id":"m3551y7xe043r8","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"Are you running the sanity check before or after training the encoder? --&gt;Before training the encoder.","created":"2024-11-06T00:33:52Z","bucket_order":4,"bucket_name":"Yesterday","type":"followup","tag_good":[],"uid_a":"a_0","children":[{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>Well that's why. The attention weight matrices $$\\mathbf{W}_q$$, $$\\mathbf{W}_k$$, and $$\\mathbf{W}_v$$ are initialized with random values, so the pre-training attention maps will naturally be very noisy. If you run the sanity check after training the encoder, there should be a much clearer structure in the attention maps.</md>","created":"2024-11-06T00:41:56Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[{"role":"student","name":"Hanyu Zhang","endorser":{},"admin":false,"photo":null,"id":"m182yvulg104ka","photo_url":null,"us":false,"facebook_id":null}],"uid":"m182yt8a22e4cr","children":[],"tag_good_arr":["m182yvulg104ka"],"id":"m355m35y98y1sg","d-bucket":"Yesterday","updated":"2024-11-06T01:08:11Z","config":{"editor":"md"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"<p>Thanks! Gotcha!</p>\n<p>And another question: What does the attention map look like for Part 2 (decoder) <strong>before and after</strong> training? Can you give me a hint so I can check it? I have only done the sanity check before training, and it looks like this:</p>\n<p></p>\n<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fm182yvulg104ka%2Fee76a2aa9e9c06808dcda4d6dc561eeb42fc42d5937ba9faf741dc0a267274b5%2F_____2024-11-05_164753.png\" width=\"724\" height=\"625\" alt=\"\" /></p>","created":"2024-11-06T00:48:43Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m355uszvv8ab","d-bucket":"Yesterday","updated":"2024-11-06T00:48:43Z","config":{"editor":"rte"}},{"anon":"no","folders":[],"data":{"embed_links":null},"subject":"<md>My pre-training decoder attention maps look pretty much like yours. My post-training decoder attention maps (some of them, anyway) look like this:\n\n![Post-training decoder attention map](/redirect/s3?bucket=uploads&prefix=paste%2Fm182yt8a22e4cr%2F4bfffc6c2dc3c443d8469d1b6316807df7bec455291137b01dbe06a03f8fe4c3%2Fdecoder_attention_map_3.png)\n\nTake my results with a grain of salt, because my perplexity values are slightly higher than expected for this assignment, so my implementation isn't 100% correct either.</md>","created":"2024-11-06T01:08:16Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid":"m182yt8a22e4cr","children":[],"tag_good_arr":[],"id":"m356jy53viu58n","d-bucket":"Yesterday","updated":"2024-11-06T01:08:26Z","config":{"editor":"md"}},{"anon":"stud","folders":[],"data":{"embed_links":null},"subject":"Thanks for the heads-up and sharing! :)","created":"2024-11-06T01:11:59Z","bucket_order":4,"bucket_name":"Yesterday","type":"feedback","tag_good":[],"uid_a":"a_0","children":[],"tag_good_arr":[],"id":"m356oqm41os71g","d-bucket":"Yesterday","updated":"2024-11-06T01:11:59Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":1,"id":"m355bpzkk32ur","d-bucket":"Yesterday","updated":"2024-11-06T01:11:59Z","config":{"editor":"rte"}},{"history_size":1,"folders":[],"data":{"embed_links":[]},"created":"2024-11-06T04:22:06Z","bucket_order":3,"tag_endorse":[],"bucket_name":"Today","history":[{"anon":"no","uid":"ku2mpmjms7n645","subject":"","created":"2024-11-06T04:22:06Z","content":"<md>Other heads’ attention map also look same? see also [](https://393)[@393](393) , [@408](408)</md>"}],"type":"i_answer","tag_endorse_arr":[],"children":[],"id":"m35dh89zubm1gx","config":{"editor":"md"},"is_tag_endorse":false},{"anon":"stud","folders":[],"data":{"embed_links":null},"no_upvotes":0,"subject":"<p><img src=\"/redirect/s3?bucket=uploads&amp;prefix=paste%2Fm182ytb8pln4cy%2F059b96b6cadafe4f792b785e4f119fa3ca7586977b7a9deee767487ea5acf86f%2FScreenshot_2024-11-06_100446.png\" width=\"527\" height=\"823\" alt=\"\" /></p>\n<p></p>\n<p>My attention maps for the encoder look like this after training. Am I doing something wrong here?</p>","created":"2024-11-06T18:09:09Z","bucket_order":3,"bucket_name":"Today","type":"followup","tag_good":[],"uid_a":"a_1","children":[],"tag_good_arr":[],"no_answer":1,"id":"m3670tgmodb7gd","updated":"2024-11-06T18:09:09Z","config":{"editor":"rte"}}],"tag_good_arr":[],"no_answer":0,"id":"m353a3wyt6p5ad","config":{"editor":"rte","has_emails_sent":1},"status":"active","drafts":{},"request_instructor":0,"request_instructor_me":false,"bookmarked":4,"num_favorites":2,"my_favorite":false,"is_bookmarked":false,"is_tag_good":false,"q_edits":[],"i_edits":[],"s_edits":[],"t":1731990406134,"default_anonymity":"no"},"error":null,"aid":"m3nydaeh3g64a0"}